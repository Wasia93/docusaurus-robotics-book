"use strict";(globalThis.webpackChunkrobotics_book=globalThis.webpackChunkrobotics_book||[]).push([[5837],{51:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"module3-isaac/isaac-ros","title":"Isaac ROS - Hardware-Accelerated Perception","description":"GPU-accelerated ROS 2 packages for real-time robotics","source":"@site/docs/module3-isaac/isaac-ros.md","sourceDirName":"module3-isaac","slug":"/module3-isaac/isaac-ros","permalink":"/docusaurus-robotics-book/sd/module3-isaac/isaac-ros","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764862720000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Isaac ROS - Hardware-Accelerated Perception","description":"GPU-accelerated ROS 2 packages for real-time robotics","keywords":["Isaac ROS","NVIDIA","GPU acceleration","VSLAM","perception","real-time"]},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Data Generation","permalink":"/docusaurus-robotics-book/sd/module3-isaac/synthetic-data"},"next":{"title":"VSLAM and Navigation","permalink":"/docusaurus-robotics-book/sd/module3-isaac/vslam-navigation"}}');var r=s(4848),a=s(8453);const l={sidebar_position:2,title:"Isaac ROS - Hardware-Accelerated Perception",description:"GPU-accelerated ROS 2 packages for real-time robotics",keywords:["Isaac ROS","NVIDIA","GPU acceleration","VSLAM","perception","real-time"]},c="Isaac ROS: Hardware-Accelerated Perception",t={},o=[{value:"Introduction to Isaac ROS",id:"introduction-to-isaac-ros",level:2},{value:"Why Isaac ROS?",id:"why-isaac-ros",level:3},{value:"Isaac ROS Packages",id:"isaac-ros-packages",level:2},{value:"Core Packages",id:"core-packages",level:3},{value:"Perception Pipeline",id:"perception-pipeline",level:3},{value:"Installation",id:"installation",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Install Isaac ROS",id:"install-isaac-ros",level:3},{value:"Isaac ROS Visual SLAM (cuVSLAM)",id:"isaac-ros-visual-slam-cuvslam",level:2},{value:"Features",id:"features",level:3},{value:"Launch cuVSLAM",id:"launch-cuvslam",level:3},{value:"Visualize in RViz",id:"visualize-in-rviz",level:3},{value:"Save and Load Maps",id:"save-and-load-maps",level:3},{value:"Isaac ROS Nvblox",id:"isaac-ros-nvblox",level:2},{value:"Features",id:"features-1",level:3},{value:"Launch Nvblox",id:"launch-nvblox",level:3},{value:"Integration with Nav2",id:"integration-with-nav2",level:3},{value:"Isaac ROS DNN Inference",id:"isaac-ros-dnn-inference",level:2},{value:"Supported Models",id:"supported-models",level:3},{value:"Convert Model to TensorRT",id:"convert-model-to-tensorrt",level:3},{value:"Run Inference with Isaac ROS",id:"run-inference-with-isaac-ros",level:3},{value:"Isaac ROS Image Processing",id:"isaac-ros-image-processing",level:2},{value:"Available Operations",id:"available-operations",level:3},{value:"Example: Gaussian Blur",id:"example-gaussian-blur",level:3},{value:"Isaac ROS AprilTag Detection",id:"isaac-ros-apriltag-detection",level:2},{value:"Launch AprilTag Detector",id:"launch-apriltag-detector",level:3},{value:"Use Cases",id:"use-cases",level:3},{value:"Integration Example: Complete Perception Stack",id:"integration-example-complete-perception-stack",level:2},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"cuVSLAM (Isaac ROS Visual SLAM)",id:"cuvslam-isaac-ros-visual-slam",level:3},{value:"Nvblox (3D Reconstruction)",id:"nvblox-3d-reconstruction",level:3},{value:"TensorRT Inference (YOLOv8n)",id:"tensorrt-inference-yolov8n",level:3},{value:"Next Steps",id:"next-steps",level:2},{value:"Lab Exercise",id:"lab-exercise",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"isaac-ros-hardware-accelerated-perception",children:"Isaac ROS: Hardware-Accelerated Perception"})}),"\n",(0,r.jsx)(n.h2,{id:"introduction-to-isaac-ros",children:"Introduction to Isaac ROS"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," is NVIDIA's collection of hardware-accelerated ROS 2 packages for robotics perception and AI:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU-accelerated"}),": Leverage CUDA and Tensor Cores"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production-ready"}),": Optimized for real-time performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real"}),": Works in Isaac Sim and on physical robots"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Open-source"}),": Available on GitHub"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"why-isaac-ros",children:"Why Isaac ROS?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Traditional ROS 2"})," runs on CPU:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"VSLAM: 10-20 FPS on CPU"}),"\n",(0,r.jsx)(n.li,{children:"Object detection: 5-10 FPS"}),"\n",(0,r.jsx)(n.li,{children:"Image processing: Variable, can be slow"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," runs on GPU:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"VSLAM: 60+ FPS on Jetson Orin"}),"\n",(0,r.jsx)(n.li,{children:"Object detection: 30+ FPS (TensorRT optimized)"}),"\n",(0,r.jsx)(n.li,{children:"Image processing: Real-time (30-60 FPS)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Performance boost"}),": 3-10x faster than CPU-only solutions."]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-packages",children:"Isaac ROS Packages"}),"\n",(0,r.jsx)(n.h3,{id:"core-packages",children:"Core Packages"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Package"}),(0,r.jsx)(n.th,{children:"Function"}),(0,r.jsx)(n.th,{children:"Acceleration"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_visual_slam"})}),(0,r.jsx)(n.td,{children:"Visual SLAM (cuVSLAM)"}),(0,r.jsx)(n.td,{children:"CUDA"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_nvblox"})}),(0,r.jsx)(n.td,{children:"3D reconstruction"}),(0,r.jsx)(n.td,{children:"CUDA"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_image_proc"})}),(0,r.jsx)(n.td,{children:"Image processing"}),(0,r.jsx)(n.td,{children:"VPI (Vision Programming Interface)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_dnn_inference"})}),(0,r.jsx)(n.td,{children:"DNN inference"}),(0,r.jsx)(n.td,{children:"TensorRT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_apriltag"})}),(0,r.jsx)(n.td,{children:"AprilTag detection"}),(0,r.jsx)(n.td,{children:"CUDA"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_stereo_image_proc"})}),(0,r.jsx)(n.td,{children:"Stereo depth"}),(0,r.jsx)(n.td,{children:"VPI"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"perception-pipeline",children:"Perception Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Camera (RealSense) \u2192 Isaac ROS Image Proc \u2192 Isaac ROS DNN Inference \u2192 Detections\n                                        \u2193\n                                Isaac ROS Visual SLAM \u2192 Odometry\n                                        \u2193\n                                Isaac ROS Nvblox \u2192 3D Map\n"})}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"NVIDIA Jetson (Orin, Xavier) or x86 with NVIDIA GPU"}),"\n",(0,r.jsx)(n.li,{children:"JetPack 5.1+ (for Jetson) or Ubuntu 22.04 (for x86)"}),"\n",(0,r.jsx)(n.li,{children:"ROS 2 Humble"}),"\n",(0,r.jsx)(n.li,{children:"CUDA 11.8+"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"install-isaac-ros",children:"Install Isaac ROS"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"On Jetson Orin Nano"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Update system\nsudo apt update && sudo apt upgrade\n\n# Install dependencies\nsudo apt install -y \\\n    libavformat-dev \\\n    libavcodec-dev \\\n    libswscale-dev \\\n    libeigen3-dev \\\n    libgflags-dev \\\n    libgoogle-glog-dev\n\n# Install Isaac ROS packages\nsudo apt install -y \\\n    ros-humble-isaac-ros-visual-slam \\\n    ros-humble-isaac-ros-nvblox \\\n    ros-humble-isaac-ros-image-proc \\\n    ros-humble-isaac-ros-dnn-inference\n\n# Source ROS 2\nsource /opt/ros/humble/setup.bash\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Verify installation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 pkg list | grep isaac_ros\n# Should list multiple isaac_ros_* packages\n"})}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-visual-slam-cuvslam",children:"Isaac ROS Visual SLAM (cuVSLAM)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"cuVSLAM"}),": CUDA-accelerated Visual Simultaneous Localization and Mapping."]}),"\n",(0,r.jsx)(n.h3,{id:"features",children:"Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time"}),": 60+ FPS on Jetson Orin"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accurate"}),": Sub-centimeter accuracy"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robust"}),": Handles dynamic scenes, lighting changes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple cameras"}),": Supports stereo, RGB-D, fisheye"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"launch-cuvslam",children:"Launch cuVSLAM"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"With RealSense D435i"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: RealSense driver\nros2 launch realsense2_camera rs_launch.py \\\n    enable_gyro:=true \\\n    enable_accel:=true \\\n    unite_imu_method:=1 \\\n    enable_infra1:=true \\\n    enable_infra2:=true\n\n# Terminal 2: Isaac ROS Visual SLAM\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Subscribed topics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/infra1/image_rect_raw"}),": Left infrared image"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/infra2/image_rect_raw"}),": Right infrared image"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/imu"}),": IMU data"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Published topics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/visual_slam/tracking/odometry"}),": Robot pose estimate (Odometry)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/visual_slam/tracking/vo_pose"}),": Visual odometry pose (PoseStamped)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/visual_slam/tracking/slam_path"}),": Full trajectory (Path)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/visual_slam/vis/observations_cloud"}),": Feature points (PointCloud2)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"visualize-in-rviz",children:"Visualize in RViz"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2\n\n# Add displays:\n# - Odometry: /visual_slam/tracking/odometry\n# - Path: /visual_slam/tracking/slam_path\n# - PointCloud2: /visual_slam/vis/observations_cloud\n# - TF\n"})}),"\n",(0,r.jsx)(n.h3,{id:"save-and-load-maps",children:"Save and Load Maps"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Save map"})," (for localization later):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 service call /visual_slam/save_map \\\n    isaac_ros_visual_slam_interfaces/srv/FilePath \\\n    \"{file_path: '/tmp/cuvslam_map.db'}\"\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Load map"})," and localize:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Add to launch file\nparameters=[{\n    'map_frame': 'map',\n    'odom_frame': 'odom',\n    'base_frame': 'base_link',\n    'enable_localization_n_mapping': False,  # Localization only\n    'load_map_from_file': True,\n    'map_file_path': '/tmp/cuvslam_map.db'\n}]\n"})}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-nvblox",children:"Isaac ROS Nvblox"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Nvblox"}),": GPU-accelerated 3D reconstruction and mapping."]}),"\n",(0,r.jsx)(n.h3,{id:"features-1",children:"Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time 3D mapping"}),": Build TSDF (Truncated Signed Distance Field) volumetric maps"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mesh generation"}),": Convert voxel map to mesh"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Obstacle detection"}),": Identify free space vs. occupied"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic updates"}),": Update map in real-time as robot moves"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"launch-nvblox",children:"Launch Nvblox"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch nvblox_examples_bringup isaac_sim_example.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Subscribed topics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/depth/image_raw"}),": Depth image (from RealSense or Isaac Sim)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/color/image_raw"}),": RGB image"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/depth/camera_info"}),": Camera intrinsics"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Published topics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/nvblox_node/mesh"}),": 3D mesh (Marker)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/nvblox_node/map_slice"}),": 2D slice of 3D map (OccupancyGrid)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/nvblox_node/tsdf_layer"}),": TSDF voxel grid"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"integration-with-nav2",children:"Integration with Nav2"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use nvblox for navigation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# navigation2 uses /map topic\n# Nvblox publishes /nvblox_node/map_slice\n\n# Remap in launch file\nremappings=[\n    ('/map', '/nvblox_node/map_slice'),\n]\n"})}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-dnn-inference",children:"Isaac ROS DNN Inference"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"TensorRT-optimized neural network inference"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"supported-models",children:"Supported Models"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object detection"}),": YOLO, RT-DETR, EfficientDet"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Segmentation"}),": U-Net, SegFormer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Classification"}),": ResNet, EfficientNet"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pose estimation"}),": OpenPose"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"convert-model-to-tensorrt",children:"Convert Model to TensorRT"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example: YOLOv8 \u2192 TensorRT"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install TensorRT Python API\npip install tensorrt\n\n# Export YOLOv8 to ONNX\nfrom ultralytics import YOLO\nmodel = YOLO('yolov8n.pt')\nmodel.export(format='onnx')\n\n# Convert ONNX to TensorRT\ntrtexec --onnx=yolov8n.onnx \\\n        --saveEngine=yolov8n.trt \\\n        --fp16  # Use FP16 for Jetson\n"})}),"\n",(0,r.jsx)(n.h3,{id:"run-inference-with-isaac-ros",children:"Run Inference with Isaac ROS"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Create DNN inference node"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nfrom cv_bridge import CvBridge\nimport tensorrt as trt\nimport pycuda.driver as cuda\nimport numpy as np\n\nclass TensorRTInferenceNode(Node):\n    def __init__(self):\n        super().__init__('tensorrt_inference')\n\n        # Load TensorRT engine\n        self.engine = self.load_engine('yolov8n.trt')\n        self.context = self.engine.create_execution_context()\n\n        # Allocate GPU memory\n        self.inputs, self.outputs, self.bindings = self.allocate_buffers()\n\n        # ROS 2\n        self.bridge = CvBridge()\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10\n        )\n        self.detection_pub = self.create_publisher(\n            Detection2DArray, '/detections', 10\n        )\n\n    def load_engine(self, engine_path):\n        with open(engine_path, 'rb') as f, trt.Runtime(trt.Logger(trt.Logger.WARNING)) as runtime:\n            return runtime.deserialize_cuda_engine(f.read())\n\n    def image_callback(self, msg):\n        # Convert to numpy\n        cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')\n\n        # Preprocess (resize, normalize)\n        input_image = self.preprocess(cv_image)\n\n        # Inference\n        outputs = self.infer(input_image)\n\n        # Postprocess (NMS, convert to Detection2DArray)\n        detections = self.postprocess(outputs, cv_image.shape)\n\n        # Publish\n        detection_msg = self.to_detection_msg(detections)\n        self.detection_pub.publish(detection_msg)\n\n    def infer(self, input_data):\n        # Copy input to GPU\n        cuda.memcpy_htod(self.inputs[0]['allocation'], input_data)\n\n        # Run inference\n        self.context.execute_v2(bindings=self.bindings)\n\n        # Copy output from GPU\n        output = np.empty(self.outputs[0]['shape'], dtype=self.outputs[0]['dtype'])\n        cuda.memcpy_dtoh(output, self.outputs[0]['allocation'])\n\n        return output\n\n# ... implement allocate_buffers, preprocess, postprocess, to_detection_msg\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Performance"}),": 30-60 FPS on Jetson Orin Nano."]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-image-processing",children:"Isaac ROS Image Processing"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"VPI (Vision Programming Interface)"}),": NVIDIA's hardware-accelerated computer vision library."]}),"\n",(0,r.jsx)(n.h3,{id:"available-operations",children:"Available Operations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gaussian blur"}),": Noise reduction"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Canny edge detection"}),": Edge extraction"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stereo disparity"}),": Depth from stereo"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Image format conversion"}),": RGB \u2194 BGR \u2194 Grayscale"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Undistortion/Rectification"}),": Camera calibration correction"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-gaussian-blur",children:"Example: Gaussian Blur"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\n\n# Using Isaac ROS image proc\nfrom isaac_ros_image_proc import ImageProcNode\n\n# Or implement manually with VPI\nimport vpi\n\nclass VPIBlurNode(Node):\n    def __init__(self):\n        super().__init__('vpi_blur')\n\n        self.bridge = CvBridge()\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10\n        )\n        self.image_pub = self.create_publisher(\n            Image, '/camera/image_blurred', 10\n        )\n\n        # VPI stream (GPU)\n        self.stream = vpi.Stream()\n\n    def image_callback(self, msg):\n        cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')\n\n        # Convert to VPI image\n        with vpi.Backend.CUDA:\n            vpi_image = vpi.asimage(cv_image)\n\n            # Gaussian blur (GPU-accelerated)\n            blurred = vpi_image.gaussian_filter(5, 1.0, stream=self.stream)\n\n            # Convert back to numpy\n            result = blurred.cpu()\n\n        # Publish\n        blurred_msg = self.bridge.cv2_to_imgmsg(result, encoding='bgr8')\n        blurred_msg.header = msg.header\n        self.image_pub.publish(blurred_msg)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Performance"}),": 10-20x faster than OpenCV on CPU."]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-apriltag-detection",children:"Isaac ROS AprilTag Detection"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"AprilTag"}),": Fiducial markers for localization and calibration."]}),"\n",(0,r.jsx)(n.h3,{id:"launch-apriltag-detector",children:"Launch AprilTag Detector"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_apriltag isaac_ros_apriltag.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Subscribed"}),": ",(0,r.jsx)(n.code,{children:"/camera/image_raw"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Published"}),": ",(0,r.jsx)(n.code,{children:"/tag_detections"})," (AprilTagDetectionArray)"]}),"\n",(0,r.jsx)(n.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robot localization"}),": Place tags at known positions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object pose estimation"}),": Tags on objects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Camera calibration"}),": Tag grid for calibration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-robot coordination"}),": Tags for robot identification"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"integration-example-complete-perception-stack",children:"Integration Example: Complete Perception Stack"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Humanoid with visual SLAM, object detection, and 3D mapping"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import IncludeLaunchDescription\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # RealSense camera\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                '/opt/ros/humble/share/realsense2_camera/launch/rs_launch.py'\n            ),\n            launch_arguments={\n                'enable_gyro': 'true',\n                'enable_accel': 'true',\n                'enable_infra1': 'true',\n                'enable_infra2': 'true',\n                'enable_depth': 'true',\n            }.items()\n        ),\n\n        # Isaac ROS Visual SLAM (cuVSLAM)\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            parameters=[{\n                'enable_image_denoising': True,\n                'rectified_images': True,\n            }],\n            remappings=[\n                ('/stereo_camera/left/image', '/camera/infra1/image_rect_raw'),\n                ('/stereo_camera/right/image', '/camera/infra2/image_rect_raw'),\n                ('/visual_slam/imu', '/camera/imu'),\n            ]\n        ),\n\n        # Isaac ROS Nvblox (3D mapping)\n        Node(\n            package='nvblox_ros',\n            executable='nvblox_node',\n            parameters=[{\n                'global_frame': 'odom',\n            }],\n            remappings=[\n                ('/depth/image', '/camera/depth/image_rect_raw'),\n                ('/depth/camera_info', '/camera/depth/camera_info'),\n                ('/color/image', '/camera/color/image_raw'),\n                ('/color/camera_info', '/camera/color/camera_info'),\n            ]\n        ),\n\n        # Object detection (TensorRT)\n        Node(\n            package='my_perception',\n            executable='tensorrt_yolo_node',\n            parameters=[{\n                'model_path': '/path/to/yolov8n.trt',\n                'confidence_threshold': 0.5,\n            }]\n        ),\n\n        # RViz visualization\n        Node(\n            package='rviz2',\n            executable='rviz2',\n            arguments=['-d', '/path/to/config.rviz']\n        ),\n    ])\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Run"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_robot perception_stack.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Result"}),": Real-time visual SLAM, 3D reconstruction, and object detection on Jetson Orin Nano."]}),"\n",(0,r.jsx)(n.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,r.jsx)(n.h3,{id:"cuvslam-isaac-ros-visual-slam",children:"cuVSLAM (Isaac ROS Visual SLAM)"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"FPS"}),(0,r.jsx)(n.th,{children:"Latency"}),(0,r.jsx)(n.th,{children:"CPU Usage"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin Nano"}),(0,r.jsx)(n.td,{children:"60 FPS"}),(0,r.jsx)(n.td,{children:"16ms"}),(0,r.jsx)(n.td,{children:"30%"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin NX"}),(0,r.jsx)(n.td,{children:"90 FPS"}),(0,r.jsx)(n.td,{children:"11ms"}),(0,r.jsx)(n.td,{children:"25%"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RTX 4080 (Desktop)"}),(0,r.jsx)(n.td,{children:"120+ FPS"}),(0,r.jsx)(n.td,{children:"under 10ms"}),(0,r.jsx)(n.td,{children:"15%"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"nvblox-3d-reconstruction",children:"Nvblox (3D Reconstruction)"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"Voxel Updates/sec"}),(0,r.jsx)(n.th,{children:"Latency"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin Nano"}),(0,r.jsx)(n.td,{children:"1M voxels/sec"}),(0,r.jsx)(n.td,{children:"30ms"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin NX"}),(0,r.jsx)(n.td,{children:"3M voxels/sec"}),(0,r.jsx)(n.td,{children:"20ms"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"tensorrt-inference-yolov8n",children:"TensorRT Inference (YOLOv8n)"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"FPS"}),(0,r.jsx)(n.th,{children:"Latency"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin Nano (FP16)"}),(0,r.jsx)(n.td,{children:"35 FPS"}),(0,r.jsx)(n.td,{children:"28ms"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin NX (FP16)"}),(0,r.jsx)(n.td,{children:"60 FPS"}),(0,r.jsx)(n.td,{children:"16ms"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RTX 4080 (FP16)"}),(0,r.jsx)(n.td,{children:"120+ FPS"}),(0,r.jsx)(n.td,{children:"under 10ms"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Comparison"}),": CPU-only YOLO runs at 5-10 FPS on same hardware."]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"You've learned Isaac ROS for hardware-accelerated perception. Next, explore VSLAM and navigation."}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"vslam-navigation",children:"Next: VSLAM and Navigation \u2192"})})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.admonition,{title:"Isaac ROS Tips",type:"tip",children:(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use Jetson"}),": Isaac ROS is optimized for Jetson (Orin, Xavier)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT models"}),": Always convert to TensorRT for best performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"FP16 precision"}),": Use FP16 on Jetson (minimal accuracy loss, 2x faster)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitor resources"}),": Use ",(0,r.jsx)(n.code,{children:"tegrastats"})," (Jetson) or ",(0,r.jsx)(n.code,{children:"nvidia-smi"})," (desktop)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronize topics"}),": Use ",(0,r.jsx)(n.code,{children:"message_filters"})," for multi-sensor fusion"]}),"\n"]})}),"\n",(0,r.jsx)(n.h2,{id:"lab-exercise",children:"Lab Exercise"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Build accelerated perception pipeline"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Install Isaac ROS"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On Jetson Orin Nano"}),"\n",(0,r.jsx)(n.li,{children:"Install cuVSLAM, Nvblox, image proc"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Setup RealSense"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Connect D435i to Jetson"}),"\n",(0,r.jsx)(n.li,{children:"Launch with IMU enabled"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Run cuVSLAM"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Launch visual SLAM"}),"\n",(0,r.jsx)(n.li,{children:"Move robot/camera around"}),"\n",(0,r.jsx)(n.li,{children:"Save map to file"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add Nvblox"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Launch 3D mapping"}),"\n",(0,r.jsx)(n.li,{children:"Build 3D map as you move"}),"\n",(0,r.jsx)(n.li,{children:"Visualize mesh in RViz"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Measure performance"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Check FPS: ",(0,r.jsx)(n.code,{children:"ros2 topic hz /visual_slam/tracking/odometry"})]}),"\n",(0,r.jsxs)(n.li,{children:["Monitor GPU: ",(0,r.jsx)(n.code,{children:"tegrastats"})]}),"\n",(0,r.jsx)(n.li,{children:"Compare to CPU-only SLAM (ORB-SLAM3)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Bonus"}),": Add TensorRT object detection, integrate all three."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>c});var i=s(6540);const r={},a=i.createContext(r);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);