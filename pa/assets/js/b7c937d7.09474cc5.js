"use strict";(globalThis.webpackChunkrobotics_book=globalThis.webpackChunkrobotics_book||[]).push([[1943],{6064:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>m,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module2-simulation/sensor-simulation","title":"Sensor Simulation","description":"Simulating LIDAR, cameras, IMUs, and depth sensors","source":"@site/docs/module2-simulation/sensor-simulation.md","sourceDirName":"module2-simulation","slug":"/module2-simulation/sensor-simulation","permalink":"/docusaurus-robotics-book/pa/module2-simulation/sensor-simulation","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764862720000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Sensor Simulation","description":"Simulating LIDAR, cameras, IMUs, and depth sensors","keywords":["sensor simulation","LIDAR","camera","IMU","depth camera","Gazebo plugins"]},"sidebar":"tutorialSidebar","previous":{"title":"Unity for Robot Visualization","permalink":"/docusaurus-robotics-book/pa/module2-simulation/unity-rendering"},"next":{"title":"URDF and SDF Formats","permalink":"/docusaurus-robotics-book/pa/module2-simulation/urdf-sdf"}}');var i=s(4848),r=s(8453);const l={sidebar_position:4,title:"Sensor Simulation",description:"Simulating LIDAR, cameras, IMUs, and depth sensors",keywords:["sensor simulation","LIDAR","camera","IMU","depth camera","Gazebo plugins"]},t="Sensor Simulation",o={},c=[{value:"Why Simulate Sensors?",id:"why-simulate-sensors",level:2},{value:"Simulation vs. Real Sensors",id:"simulation-vs-real-sensors",level:3},{value:"Camera Simulation",id:"camera-simulation",level:2},{value:"RGB Camera in Gazebo",id:"rgb-camera-in-gazebo",level:3},{value:"Depth Camera (RGB-D)",id:"depth-camera-rgb-d",level:3},{value:"Stereo Camera",id:"stereo-camera",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:2},{value:"2D LIDAR (Laser Scanner)",id:"2d-lidar-laser-scanner",level:3},{value:"3D LIDAR (Point Cloud)",id:"3d-lidar-point-cloud",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"Contact Sensors (Force/Torque)",id:"contact-sensors-forcetorque",level:2},{value:"GPS Simulation",id:"gps-simulation",level:2},{value:"Noise Models",id:"noise-models",level:2},{value:"Types of Noise",id:"types-of-noise",level:3},{value:"Realistic Noise Parameters",id:"realistic-noise-parameters",level:3},{value:"Sensor Update Rates",id:"sensor-update-rates",level:2},{value:"Visualizing Sensor Data",id:"visualizing-sensor-data",level:2},{value:"In Gazebo",id:"in-gazebo",level:3},{value:"In RViz",id:"in-rviz",level:3},{value:"Testing Sensors",id:"testing-sensors",level:2},{value:"Test 1: Camera",id:"test-1-camera",level:3},{value:"Test 2: LIDAR",id:"test-2-lidar",level:3},{value:"Test 3: IMU",id:"test-3-imu",level:3},{value:"Multi-Sensor Fusion Example",id:"multi-sensor-fusion-example",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Lab Exercise",id:"lab-exercise",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sensor-simulation",children:"Sensor Simulation"})}),"\n",(0,i.jsx)(n.h2,{id:"why-simulate-sensors",children:"Why Simulate Sensors?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Accurate sensor simulation"})," is critical for:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Algorithm development"}),": Test perception before hardware"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data generation"}),": Create labeled datasets for ML"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Edge case testing"}),": Simulate rare scenarios (fog, darkness, sensor failures)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost savings"}),": No need to buy expensive sensors during development"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"simulation-vs-real-sensors",children:"Simulation vs. Real Sensors"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Real Sensor"}),(0,i.jsx)(n.th,{children:"Simulated Sensor"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Cost"})}),(0,i.jsx)(n.td,{children:"$100-5,000"}),(0,i.jsx)(n.td,{children:"Free"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Setup Time"})}),(0,i.jsx)(n.td,{children:"Hours (mounting, calibration)"}),(0,i.jsx)(n.td,{children:"Minutes (add plugin)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Noise"})}),(0,i.jsx)(n.td,{children:"Real-world noise patterns"}),(0,i.jsx)(n.td,{children:"Approximate (Gaussian)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Edge Cases"})}),(0,i.jsx)(n.td,{children:"Hard to reproduce"}),(0,i.jsx)(n.td,{children:"Easy (fog, occlusion, etc.)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Accuracy"})}),(0,i.jsx)(n.td,{children:"Ground truth"}),(0,i.jsx)(n.td,{children:"Approximation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Data Volume"})}),(0,i.jsx)(n.td,{children:"Limited by recording"}),(0,i.jsx)(n.td,{children:"Unlimited"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best approach"}),": Develop with simulation, validate with real sensors."]}),"\n",(0,i.jsx)(n.h2,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"rgb-camera-in-gazebo",children:"RGB Camera in Gazebo"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Add to URDF"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="camera_link">\n  <sensor type="camera" name="head_camera">\n    <update_rate>30.0</update_rate>\n    <camera name="head_camera">\n      \x3c!-- Field of view --\x3e\n      <horizontal_fov>1.3962634</horizontal_fov>  \x3c!-- 80 degrees --\x3e\n\n      \x3c!-- Image settings --\x3e\n      <image>\n        <width>1920</width>\n        <height>1080</height>\n        <format>R8G8B8</format>  \x3c!-- RGB --\x3e\n      </image>\n\n      \x3c!-- Clipping planes --\x3e\n      <clip>\n        <near>0.02</near>  \x3c!-- 2cm minimum --\x3e\n        <far>300</far>     \x3c!-- 300m maximum --\x3e\n      </clip>\n\n      \x3c!-- Lens distortion (optional, for realism) --\x3e\n      <distortion>\n        <k1>0.0</k1>  \x3c!-- Radial distortion --\x3e\n        <k2>0.0</k2>\n        <k3>0.0</k3>\n        <p1>0.0</p1>  \x3c!-- Tangential distortion --\x3e\n        <p2>0.0</p2>\n        <center>0.5 0.5</center>\n      </distortion>\n\n      \x3c!-- Noise model --\x3e\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.007</stddev>  \x3c!-- ~2/255 pixel noise --\x3e\n      </noise>\n    </camera>\n\n    \x3c!-- ROS 2 plugin --\x3e\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n      <ros>\n        <namespace>/camera</namespace>\n        <remapping>image_raw:=image_raw</remapping>\n        <remapping>camera_info:=camera_info</remapping>\n      </ros>\n      <camera_name>head_camera</camera_name>\n      <frame_name>camera_link</frame_name>\n      <hack_baseline>0.07</hack_baseline>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topics published"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/camera/image_raw"}),": Raw RGB image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/camera/camera_info"}),": Camera calibration (K matrix, distortion)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"depth-camera-rgb-d",children:"Depth Camera (RGB-D)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Simulates Intel RealSense, Kinect"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="depth_camera_link">\n  <sensor type="depth" name="depth_camera">\n    <update_rate>30.0</update_rate>\n    <camera name="depth_camera">\n      <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\n      <image>\n        <width>640</width>\n        <height>480</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.05</near>\n        <far>10.0</far>\n      </clip>\n    </camera>\n\n    <plugin name="depth_camera_controller" filename="libgazebo_ros_camera.so">\n      <ros>\n        <namespace>/depth_camera</namespace>\n      </ros>\n      <camera_name>depth_camera</camera_name>\n      <frame_name>depth_camera_link</frame_name>\n\n      \x3c!-- Publish both RGB and depth --\x3e\n      <min_depth>0.05</min_depth>\n      <max_depth>10.0</max_depth>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topics"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/depth_camera/image_raw"}),": RGB image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/depth_camera/depth/image_raw"}),": Depth image (16-bit, millimeters)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/depth_camera/points"}),": Point cloud (PointCloud2)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"stereo-camera",children:"Stereo Camera"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Two cameras for depth estimation"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Left camera --\x3e\n<gazebo reference="left_camera_link">\n  <sensor type="camera" name="left_camera">\n    \x3c!-- Same as RGB camera config --\x3e\n    <plugin name="left_camera_controller" filename="libgazebo_ros_camera.so">\n      <ros><namespace>/stereo/left</namespace></ros>\n      <camera_name>left</camera_name>\n      <frame_name>left_camera_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n\n\x3c!-- Right camera (offset by baseline) --\x3e\n<gazebo reference="right_camera_link">\n  <sensor type="camera" name="right_camera">\n    <plugin name="right_camera_controller" filename="libgazebo_ros_camera.so">\n      <ros><namespace>/stereo/right</namespace></ros>\n      <camera_name>right</camera_name>\n      <frame_name>right_camera_link</frame_name>\n      <hack_baseline>0.07</hack_baseline>  \x3c!-- 7cm baseline --\x3e\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Post-processing"}),": Use ",(0,i.jsx)(n.code,{children:"stereo_image_proc"})," to compute disparity and depth."]}),"\n",(0,i.jsx)(n.h2,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"2d-lidar-laser-scanner",children:"2D LIDAR (Laser Scanner)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Simulates RPLIDAR, SICK, Hokuyo"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="lidar_link">\n  <sensor type="ray" name="lidar">\n    <pose>0 0 0 0 0 0</pose>\n    <visualize>true</visualize>  \x3c!-- Show rays in Gazebo --\x3e\n    <update_rate>10</update_rate>\n\n    <ray>\n      \x3c!-- Scan parameters --\x3e\n      <scan>\n        <horizontal>\n          <samples>720</samples>  \x3c!-- 720 points --\x3e\n          <resolution>1</resolution>\n          <min_angle>-3.14159</min_angle>  \x3c!-- -180 degrees --\x3e\n          <max_angle>3.14159</max_angle>   \x3c!-- +180 degrees --\x3e\n        </horizontal>\n      </scan>\n\n      \x3c!-- Range parameters --\x3e\n      <range>\n        <min>0.10</min>  \x3c!-- 10cm minimum --\x3e\n        <max>30.0</max>  \x3c!-- 30m maximum --\x3e\n        <resolution>0.01</resolution>  \x3c!-- 1cm resolution --\x3e\n      </range>\n\n      \x3c!-- Noise model --\x3e\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.01</stddev>  \x3c!-- 1cm noise --\x3e\n      </noise>\n    </ray>\n\n    <plugin name="gazebo_ros_lidar" filename="libgazebo_ros_ray_sensor.so">\n      <ros>\n        <namespace>/lidar</namespace>\n        <remapping>~/out:=scan</remapping>\n      </ros>\n      <output_type>sensor_msgs/LaserScan</output_type>\n      <frame_name>lidar_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topic"}),": ",(0,i.jsx)(n.code,{children:"/lidar/scan"})," (LaserScan message)"]}),"\n",(0,i.jsx)(n.h3,{id:"3d-lidar-point-cloud",children:"3D LIDAR (Point Cloud)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Simulates Velodyne, Ouster"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="lidar_3d_link">\n  <sensor type="ray" name="lidar_3d">\n    <update_rate>10</update_rate>\n    <ray>\n      <scan>\n        \x3c!-- Horizontal scan --\x3e\n        <horizontal>\n          <samples>1800</samples>  \x3c!-- 0.2 degree resolution --\x3e\n          <resolution>1</resolution>\n          <min_angle>-3.14159</min_angle>\n          <max_angle>3.14159</max_angle>\n        </horizontal>\n\n        \x3c!-- Vertical scan (16 or 32 channels) --\x3e\n        <vertical>\n          <samples>16</samples>  \x3c!-- 16-channel LIDAR --\x3e\n          <resolution>1</resolution>\n          <min_angle>-0.261799</min_angle>  \x3c!-- -15 degrees --\x3e\n          <max_angle>0.261799</max_angle>   \x3c!-- +15 degrees --\x3e\n        </vertical>\n      </scan>\n\n      <range>\n        <min>0.5</min>\n        <max>100.0</max>\n        <resolution>0.01</resolution>\n      </range>\n\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.02</stddev>\n      </noise>\n    </ray>\n\n    <plugin name="gazebo_ros_3d_lidar" filename="libgazebo_ros_ray_sensor.so">\n      <ros><namespace>/lidar_3d</namespace></ros>\n      <output_type>sensor_msgs/PointCloud2</output_type>\n      <frame_name>lidar_3d_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topic"}),": ",(0,i.jsx)(n.code,{children:"/lidar_3d/points"})," (PointCloud2 message)"]}),"\n",(0,i.jsx)(n.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Inertial Measurement Unit"})," (accelerometer + gyroscope):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="imu_link">\n  <gravity>true</gravity>\n  <sensor name="imu_sensor" type="imu">\n    <always_on>true</always_on>\n    <update_rate>100</update_rate>  \x3c!-- 100 Hz typical --\x3e\n\n    <imu>\n      \x3c!-- Angular velocity (gyroscope) --\x3e\n      <angular_velocity>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>  \x3c!-- rad/s --\x3e\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>\n          </noise>\n        </z>\n      </angular_velocity>\n\n      \x3c!-- Linear acceleration (accelerometer) --\x3e\n      <linear_acceleration>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>  \x3c!-- m/s\xb2 --\x3e\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>\n          </noise>\n        </z>\n      </linear_acceleration>\n    </imu>\n\n    <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\n      <ros>\n        <namespace>/imu</namespace>\n        <remapping>~/out:=data</remapping>\n      </ros>\n      <initial_orientation_as_reference>false</initial_orientation_as_reference>\n      <frame_name>imu_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topic"}),": ",(0,i.jsx)(n.code,{children:"/imu/data"})," (Imu message)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Fields"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"orientation"}),": Quaternion (roll, pitch, yaw)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"angular_velocity"}),": rad/s (x, y, z)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"linear_acceleration"}),": m/s\xb2 (x, y, z)"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"contact-sensors-forcetorque",children:"Contact Sensors (Force/Torque)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Detect collisions and measure forces"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="foot_link">\n  <sensor name="foot_contact_sensor" type="contact">\n    <always_on>true</always_on>\n    <update_rate>100.0</update_rate>\n\n    <contact>\n      <collision>foot_collision</collision>  \x3c!-- Must match collision name --\x3e\n    </contact>\n\n    <plugin name="gazebo_ros_bumper" filename="libgazebo_ros_bumper.so">\n      <ros>\n        <namespace>/foot</namespace>\n        <remapping>bumper_states:=contact</remapping>\n      </ros>\n      <frame_name>foot_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topic"}),": ",(0,i.jsx)(n.code,{children:"/foot/contact"})," (ContactsState message)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use case"}),": Detect when foot touches ground for bipedal walking."]}),"\n",(0,i.jsx)(n.h2,{id:"gps-simulation",children:"GPS Simulation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"For outdoor navigation"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo>\n  <plugin name="gazebo_ros_gps" filename="libgazebo_ros_gps_sensor.so">\n    <ros>\n      <namespace>/gps</namespace>\n      <remapping>~/out:=fix</remapping>\n    </ros>\n    <frame_name>base_link</frame_name>\n\n    \x3c!-- GPS accuracy --\x3e\n    <position_sensing>\n      <horizontal>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>2.0</stddev>  \x3c!-- 2m horizontal error --\x3e\n        </noise>\n      </horizontal>\n      <vertical>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>4.0</stddev>  \x3c!-- 4m vertical error --\x3e\n        </noise>\n      </vertical>\n    </position_sensing>\n\n    \x3c!-- Update rate --\x3e\n    <update_rate>1.0</update_rate>  \x3c!-- 1 Hz typical --\x3e\n  </plugin>\n</gazebo>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 topic"}),": ",(0,i.jsx)(n.code,{children:"/gps/fix"})," (NavSatFix message)"]}),"\n",(0,i.jsx)(n.h2,{id:"noise-models",children:"Noise Models"}),"\n",(0,i.jsx)(n.h3,{id:"types-of-noise",children:"Types of Noise"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Gaussian (Normal Distribution)"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<noise>\n  <type>gaussian</type>\n  <mean>0.0</mean>\n  <stddev>0.01</stddev>  \x3c!-- Standard deviation --\x3e\n</noise>\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Uniform (Random within range)"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<noise>\n  <type>uniform</type>\n  <min>-0.05</min>\n  <max>0.05</max>\n</noise>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"realistic-noise-parameters",children:"Realistic Noise Parameters"}),"\n",(0,i.jsx)(n.p,{children:"Based on real sensor specs:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Sensor"}),(0,i.jsx)(n.th,{children:"Parameter"}),(0,i.jsx)(n.th,{children:"Noise (stddev)"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Camera"})}),(0,i.jsx)(n.td,{children:"Pixel intensity"}),(0,i.jsx)(n.td,{children:"0.007 (2/255)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Depth Camera"})}),(0,i.jsx)(n.td,{children:"Depth (RealSense)"}),(0,i.jsx)(n.td,{children:"0.01m (1cm)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"LIDAR"})}),(0,i.jsx)(n.td,{children:"Range"}),(0,i.jsx)(n.td,{children:"0.01-0.03m"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"IMU Gyro"})}),(0,i.jsx)(n.td,{children:"Angular velocity"}),(0,i.jsx)(n.td,{children:"0.0002 rad/s"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"IMU Accel"})}),(0,i.jsx)(n.td,{children:"Linear accel"}),(0,i.jsx)(n.td,{children:"0.017 m/s\xb2"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"GPS"})}),(0,i.jsx)(n.td,{children:"Horizontal position"}),(0,i.jsx)(n.td,{children:"2.0m"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"GPS"})}),(0,i.jsx)(n.td,{children:"Vertical position"}),(0,i.jsx)(n.td,{children:"4.0m"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Source"}),": Manufacturer datasheets (Intel, Velodyne, etc.)"]}),"\n",(0,i.jsx)(n.h2,{id:"sensor-update-rates",children:"Sensor Update Rates"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Match real sensor frequencies"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Sensor"}),(0,i.jsx)(n.th,{children:"Typical Rate"}),(0,i.jsx)(n.th,{children:"Gazebo Update Rate"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Camera"})}),(0,i.jsx)(n.td,{children:"30-60 Hz"}),(0,i.jsx)(n.td,{children:"30 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Depth Camera"})}),(0,i.jsx)(n.td,{children:"30-90 Hz"}),(0,i.jsx)(n.td,{children:"30 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"2D LIDAR"})}),(0,i.jsx)(n.td,{children:"5-10 Hz"}),(0,i.jsx)(n.td,{children:"10 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"3D LIDAR"})}),(0,i.jsx)(n.td,{children:"10-20 Hz"}),(0,i.jsx)(n.td,{children:"10 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"IMU"})}),(0,i.jsx)(n.td,{children:"100-1000 Hz"}),(0,i.jsx)(n.td,{children:"100 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"GPS"})}),(0,i.jsx)(n.td,{children:"1-10 Hz"}),(0,i.jsx)(n.td,{children:"1 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Contact Sensor"})}),(0,i.jsx)(n.td,{children:"100-1000 Hz"}),(0,i.jsx)(n.td,{children:"100 Hz"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Trade-off"}),": Higher rates = more data but slower simulation."]}),"\n",(0,i.jsx)(n.h2,{id:"visualizing-sensor-data",children:"Visualizing Sensor Data"}),"\n",(0,i.jsx)(n.h3,{id:"in-gazebo",children:"In Gazebo"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"View \u2192 Contacts (visualize contact points)\nView \u2192 Transparent (see through objects)\n"})}),"\n",(0,i.jsx)(n.p,{children:"For ray sensors (LIDAR):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<visualize>true</visualize>  \x3c!-- Show laser rays --\x3e\n"})}),"\n",(0,i.jsx)(n.h3,{id:"in-rviz",children:"In RViz"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2\n\n# Add displays:\n# - Camera: Subscribe to /camera/image_raw\n# - LaserScan: Subscribe to /lidar/scan\n# - PointCloud2: Subscribe to /lidar_3d/points\n# - Imu: Subscribe to /imu/data (shows orientation)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"testing-sensors",children:"Testing Sensors"}),"\n",(0,i.jsx)(n.h3,{id:"test-1-camera",children:"Test 1: Camera"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Launch Gazebo with robot\nros2 launch my_robot gazebo.launch.py\n\n# Terminal 2: View camera stream\nros2 run rqt_image_view rqt_image_view /camera/image_raw\n\n# Terminal 3: Check topic info\nros2 topic info /camera/image_raw\nros2 topic hz /camera/image_raw  # Should be ~30 Hz\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-2-lidar",children:"Test 2: LIDAR"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Launch Gazebo\nros2 launch my_robot gazebo.launch.py\n\n# Terminal 2: View LIDAR in RViz\nros2 run rviz2 rviz2\n# Add LaserScan display \u2192 Topic: /lidar/scan\n\n# Terminal 3: Echo data\nros2 topic echo /lidar/scan --no-arr  # Suppress large arrays\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-3-imu",children:"Test 3: IMU"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Launch Gazebo\nros2 launch my_robot gazebo.launch.py\n\n# Terminal 2: Echo IMU data\nros2 topic echo /imu/data\n\n# Tilt robot in Gazebo (use mouse to rotate)\n# Should see orientation change in IMU data\n"})}),"\n",(0,i.jsx)(n.h2,{id:"multi-sensor-fusion-example",children:"Multi-Sensor Fusion Example"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Combine camera + LIDAR for better perception"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan\nimport cv2\nfrom cv_bridge import CvBridge\n\nclass SensorFusionNode(Node):\n    def __init__(self):\n        super().__init__('sensor_fusion')\n\n        self.bridge = CvBridge()\n        self.latest_image = None\n        self.latest_scan = None\n\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10\n        )\n        self.scan_sub = self.create_subscription(\n            LaserScan, '/lidar/scan', self.scan_callback, 10\n        )\n\n    def image_callback(self, msg):\n        self.latest_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')\n        self.fuse_data()\n\n    def scan_callback(self, msg):\n        self.latest_scan = msg\n        self.fuse_data()\n\n    def fuse_data(self):\n        if self.latest_image is None or self.latest_scan is None:\n            return\n\n        # Example: Overlay LIDAR data on camera image\n        # Project LIDAR points to image plane\n        # (Requires camera-LIDAR extrinsic calibration)\n\n        self.get_logger().info('Fusing camera + LIDAR data')\n"})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"You've learned sensor simulation. Next, understand robot description formats (URDF vs SDF)."}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"urdf-sdf",children:"Next: URDF and SDF \u2192"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.admonition,{title:"Sensor Simulation Tips",type:"tip",children:(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Start with defaults"}),": Don't over-tune noise initially"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Match real specs"}),": Use manufacturer datasheets for realistic noise"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test incrementally"}),": Add one sensor at a time"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visualize"}),": Use RViz to debug sensor placement and data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Profile performance"}),": Too many high-rate sensors slow simulation"]}),"\n"]})}),"\n",(0,i.jsx)(n.h2,{id:"lab-exercise",children:"Lab Exercise"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Build a multi-sensor humanoid"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Add sensors to URDF"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Head: RGB camera (30 Hz, 1920x1080)"}),"\n",(0,i.jsx)(n.li,{children:"Head: Depth camera (30 Hz, 640x480)"}),"\n",(0,i.jsx)(n.li,{children:"Torso: IMU (100 Hz)"}),"\n",(0,i.jsx)(n.li,{children:"Torso: 2D LIDAR (10 Hz, 360\xb0)"}),"\n",(0,i.jsx)(n.li,{children:"Feet: Contact sensors (100 Hz)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Configure noise"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Camera: stddev 0.007"}),"\n",(0,i.jsx)(n.li,{children:"Depth: stddev 0.01m"}),"\n",(0,i.jsx)(n.li,{children:"LIDAR: stddev 0.02m"}),"\n",(0,i.jsx)(n.li,{children:"IMU: gyro 0.0002 rad/s, accel 0.017 m/s\xb2"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Test in Gazebo"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Spawn robot"}),"\n",(0,i.jsx)(n.li,{children:"Verify all topics publishing"}),"\n",(0,i.jsxs)(n.li,{children:["Check update rates with ",(0,i.jsx)(n.code,{children:"ros2 topic hz"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visualize in RViz"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Camera image"}),"\n",(0,i.jsx)(n.li,{children:"LIDAR scan"}),"\n",(0,i.jsx)(n.li,{children:"IMU orientation"}),"\n",(0,i.jsx)(n.li,{children:"Robot TF tree"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Bonus"}),": Create sensor fusion node that combines camera + LIDAR."]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>t});var a=s(6540);const i={},r=a.createContext(i);function l(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);