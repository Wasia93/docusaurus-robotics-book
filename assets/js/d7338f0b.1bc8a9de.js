"use strict";(globalThis.webpackChunkrobotics_book=globalThis.webpackChunkrobotics_book||[]).push([[6930],{7073:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module3-isaac/vslam-navigation","title":"VSLAM and Navigation","description":"Visual SLAM for localization and autonomous navigation","source":"@site/docs/module3-isaac/vslam-navigation.md","sourceDirName":"module3-isaac","slug":"/module3-isaac/vslam-navigation","permalink":"/module3-isaac/vslam-navigation","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1764862720000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"VSLAM and Navigation","description":"Visual SLAM for localization and autonomous navigation","keywords":["VSLAM","visual SLAM","localization","mapping","navigation","cuVSLAM"]},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS - Hardware-Accelerated Perception","permalink":"/module3-isaac/isaac-ros"},"next":{"title":"Nav2 for Bipedal Humanoids","permalink":"/module3-isaac/nav2-bipedal"}}');var a=i(4848),l=i(8453);const r={sidebar_position:3,title:"VSLAM and Navigation",description:"Visual SLAM for localization and autonomous navigation",keywords:["VSLAM","visual SLAM","localization","mapping","navigation","cuVSLAM"]},o="VSLAM and Navigation",t={},c=[{value:"Visual SLAM Overview",id:"visual-slam-overview",level:2},{value:"The SLAM Problem",id:"the-slam-problem",level:2},{value:"SLAM Components",id:"slam-components",level:3},{value:"cuVSLAM: NVIDIA&#39;s Visual SLAM",id:"cuvslam-nvidias-visual-slam",level:2},{value:"Features",id:"features",level:3},{value:"System Architecture",id:"system-architecture",level:3},{value:"Running cuVSLAM",id:"running-cuvslam",level:2},{value:"With RealSense D435i",id:"with-realsense-d435i",level:3},{value:"Published Topics",id:"published-topics",level:3},{value:"Visualizing SLAM in RViz",id:"visualizing-slam-in-rviz",level:2},{value:"Mapping Workflow",id:"mapping-workflow",level:2},{value:"Phase 1: Exploration (Mapping)",id:"phase-1-exploration-mapping",level:3},{value:"Phase 2: Localization (Using Map)",id:"phase-2-localization-using-map",level:3},{value:"Integrating VSLAM with Navigation",id:"integrating-vslam-with-navigation",level:2},{value:"Nav2 Integration",id:"nav2-integration",level:3},{value:"Complete Navigation Stack",id:"complete-navigation-stack",level:3},{value:"Sending Navigation Goals",id:"sending-navigation-goals",level:3},{value:"Troubleshooting VSLAM",id:"troubleshooting-vslam",level:2},{value:"Problem: Tracking Lost",id:"problem-tracking-lost",level:3},{value:"Problem: Drift (Map Not Closing)",id:"problem-drift-map-not-closing",level:3},{value:"Problem: Poor Performance (Low FPS)",id:"problem-poor-performance-low-fps",level:3},{value:"Advanced: Multi-Camera VSLAM",id:"advanced-multi-camera-vslam",level:2},{value:"Performance Tuning",id:"performance-tuning",level:2},{value:"Parameters for Speed",id:"parameters-for-speed",level:3},{value:"Parameters for Accuracy",id:"parameters-for-accuracy",level:3},{value:"Comparison: cuVSLAM vs. ORB-SLAM3",id:"comparison-cuvslam-vs-orb-slam3",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Lab Exercise",id:"lab-exercise",level:2}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"vslam-and-navigation",children:"VSLAM and Navigation"})}),"\n",(0,a.jsx)(e.h2,{id:"visual-slam-overview",children:"Visual SLAM Overview"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"VSLAM (Visual Simultaneous Localization and Mapping)"})," enables robots to:"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Build a map"})," of unknown environment"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Localize"})," itself within that map"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Navigate"})," autonomously using the map"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Why Visual SLAM?"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Uses cameras (cheaper than LIDAR)"}),"\n",(0,a.jsx)(e.li,{children:"Rich visual information (landmarks, textures)"}),"\n",(0,a.jsx)(e.li,{children:"Works indoors and outdoors"}),"\n",(0,a.jsx)(e.li,{children:"Scales to large environments"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"the-slam-problem",children:"The SLAM Problem"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Goal"}),": Estimate robot pose (x, y, \u03b8) AND map simultaneously."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Challenge"}),": Chicken-and-egg problem:"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Need map to localize"}),"\n",(0,a.jsx)(e.li,{children:"Need pose to build map"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solution"}),": Solve jointly using Bayesian filtering."]}),"\n",(0,a.jsx)(e.h3,{id:"slam-components",children:"SLAM Components"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"Camera Images \u2192 Feature Extraction \u2192 Feature Matching \u2192 Pose Estimation\n                                                              \u2193\n                                                        Loop Closure\n                                                              \u2193\n                                                     Bundle Adjustment\n                                                              \u2193\n                                                     Optimized Map + Pose\n"})}),"\n",(0,a.jsx)(e.h2,{id:"cuvslam-nvidias-visual-slam",children:"cuVSLAM: NVIDIA's Visual SLAM"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"cuVSLAM"})," (CUDA Visual SLAM) is NVIDIA's GPU-accelerated SLAM solution."]}),"\n",(0,a.jsx)(e.h3,{id:"features",children:"Features"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Real-time"}),": 60+ FPS on Jetson Orin"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Multiple sensors"}),": Stereo, RGB-D, mono+IMU, fisheye"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Loop closure"}),": Detects revisited locations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Global optimization"}),": Bundle adjustment on GPU"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Map persistence"}),": Save/load maps for localization"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"system-architecture",children:"System Architecture"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Sensors (Camera + IMU)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Visual Odometry (VO)                  \u2502\n\u2502  - Feature extraction (GPU)            \u2502\n\u2502  - Feature tracking (GPU)              \u2502\n\u2502  - Pose estimation                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Mapping                               \u2502\n\u2502  - Keyframe selection                  \u2502\n\u2502  - 3D point triangulation              \u2502\n\u2502  - Local map optimization              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Loop Closure                          \u2502\n\u2502  - Place recognition (GPU)             \u2502\n\u2502  - Loop constraint generation          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Global Optimization                   \u2502\n\u2502  - Pose graph optimization             \u2502\n\u2502  - Bundle adjustment (GPU)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(e.h2,{id:"running-cuvslam",children:"Running cuVSLAM"}),"\n",(0,a.jsx)(e.h3,{id:"with-realsense-d435i",children:"With RealSense D435i"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Launch file"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # RealSense camera with IMU\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                '/opt/ros/humble/share/realsense2_camera/launch/rs_launch.py'\n            ),\n            launch_arguments={\n                'enable_gyro': 'true',\n                'enable_accel': 'true',\n                'unite_imu_method': '1',  # Linear interpolation\n                'enable_infra1': 'true',\n                'enable_infra2': 'true',\n                'enable_depth': 'false',  # Not needed for stereo SLAM\n            }.items()\n        ),\n\n        # cuVSLAM\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            name='visual_slam',\n            parameters=[{\n                'enable_rectified_pose': True,\n                'enable_slam_visualization': True,\n                'enable_landmarks_view': True,\n                'enable_observations_view': True,\n                'num_cameras': 2,  # Stereo\n                'min_num_images': 2,\n                'enable_image_denoising': True,\n                'rectified_images': True,\n                'enable_imu_fusion': True,\n            }],\n            remappings=[\n                ('/stereo_camera/left/image', '/camera/infra1/image_rect_raw'),\n                ('/stereo_camera/left/camera_info', '/camera/infra1/camera_info'),\n                ('/stereo_camera/right/image', '/camera/infra2/image_rect_raw'),\n                ('/stereo_camera/right/camera_info', '/camera/infra2/camera_info'),\n                ('/visual_slam/imu', '/camera/imu'),\n            ],\n            output='screen'\n        ),\n    ])\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Run"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"ros2 launch my_robot vslam.launch.py\n"})}),"\n",(0,a.jsx)(e.h3,{id:"published-topics",children:"Published Topics"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"/visual_slam/tracking/odometry           # Odometry (nav_msgs/Odometry)\n/visual_slam/tracking/vo_pose            # Visual odometry pose\n/visual_slam/tracking/slam_path          # Full trajectory (Path)\n/visual_slam/tracking/vo_pose_covariance # Pose uncertainty\n/visual_slam/vis/observations_cloud      # Observed features (PointCloud2)\n/visual_slam/vis/landmarks_cloud         # Map landmarks (PointCloud2)\n/visual_slam/vis/loop_closure_cloud      # Loop closure matches\n/tf                                      # Transforms (base_link \u2192 odom)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"visualizing-slam-in-rviz",children:"Visualizing SLAM in RViz"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Launch RViz\nros2 run rviz2 rviz2\n\n# Add displays:\n# 1. Odometry: /visual_slam/tracking/odometry (show robot pose)\n# 2. Path: /visual_slam/tracking/slam_path (show trajectory)\n# 3. PointCloud2: /visual_slam/vis/landmarks_cloud (show map)\n# 4. PointCloud2: /visual_slam/vis/observations_cloud (show features)\n# 5. TF: Show all transforms\n# 6. Image: /camera/infra1/image_rect_raw (show camera view)\n\n# Set fixed frame: odom\n"})}),"\n",(0,a.jsx)(e.h2,{id:"mapping-workflow",children:"Mapping Workflow"}),"\n",(0,a.jsx)(e.h3,{id:"phase-1-exploration-mapping",children:"Phase 1: Exploration (Mapping)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Goal"}),": Build a map by exploring environment."]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# 1. Launch VSLAM in mapping mode (default)\nros2 launch my_robot vslam.launch.py\n\n# 2. Teleoperate robot to explore\nros2 run teleop_twist_keyboard teleop_twist_keyboard\n\n# 3. Move slowly through environment\n#    - Cover all areas\n#    - Look at textured surfaces\n#    - Return to starting point (for loop closure)\n\n# 4. Monitor map quality\nros2 topic echo /visual_slam/tracking/vo_pose_covariance\n# Low covariance = high confidence\n\n# 5. Save map\nros2 service call /visual_slam/save_map \\\n    isaac_ros_visual_slam_interfaces/srv/FilePath \\\n    \"{file_path: '/home/user/maps/my_map.db'}\"\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Best practices for mapping"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Move slowly (< 0.5 m/s)"}),"\n",(0,a.jsx)(e.li,{children:"Avoid fast rotations"}),"\n",(0,a.jsx)(e.li,{children:"Look at textured surfaces (not blank walls)"}),"\n",(0,a.jsx)(e.li,{children:"Revisit starting location (enables loop closure)"}),"\n",(0,a.jsx)(e.li,{children:"Map in good lighting"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"phase-2-localization-using-map",children:"Phase 2: Localization (Using Map)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Goal"}),": Localize in pre-built map."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Modify launch file"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"Node(\n    package='isaac_ros_visual_slam',\n    executable='isaac_ros_visual_slam',\n    parameters=[{\n        'enable_localization_n_mapping': False,  # Localization only\n        'load_map_from_file': True,\n        'map_file_path': '/home/user/maps/my_map.db',\n    }],\n    # ... rest of config\n)\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Run"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"ros2 launch my_robot vslam_localization.launch.py\n\n# Robot will localize in existing map\n# No new landmarks added, only tracking\n"})}),"\n",(0,a.jsx)(e.h2,{id:"integrating-vslam-with-navigation",children:"Integrating VSLAM with Navigation"}),"\n",(0,a.jsx)(e.h3,{id:"nav2-integration",children:"Nav2 Integration"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Nav2"})," (Navigation 2) uses VSLAM odometry for navigation."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Architecture"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"cuVSLAM (/visual_slam/tracking/odometry) \u2192 Nav2 (/odom)\n                                               \u2193\n                                          Path Planner\n                                               \u2193\n                                        Controller (/cmd_vel)\n                                               \u2193\n                                          Robot moves\n"})}),"\n",(0,a.jsx)(e.h3,{id:"complete-navigation-stack",children:"Complete Navigation Stack"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Launch file"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import IncludeLaunchDescription\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # 1. Camera + VSLAM (as before)\n        IncludeLaunchDescription(...),\n\n        # 2. Robot state publisher\n        Node(\n            package='robot_state_publisher',\n            executable='robot_state_publisher',\n            parameters=[{'robot_description': robot_description}]\n        ),\n\n        # 3. Nvblox (3D mapping for obstacle avoidance)\n        Node(\n            package='nvblox_ros',\n            executable='nvblox_node',\n            parameters=[{\n                'global_frame': 'odom',\n            }],\n            remappings=[\n                ('/depth/image', '/camera/depth/image_rect_raw'),\n                ('/color/image', '/camera/color/image_raw'),\n            ]\n        ),\n\n        # 4. Nav2\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                '/opt/ros/humble/share/nav2_bringup/launch/navigation_launch.py'\n            ),\n            launch_arguments={\n                'use_sim_time': 'false',\n                'params_file': '/path/to/nav2_params.yaml',\n            }.items()\n        ),\n    ])\n"})}),"\n",(0,a.jsx)(e.h3,{id:"sending-navigation-goals",children:"Sending Navigation Goals"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Command-line"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"ros2 topic pub /goal_pose geometry_msgs/PoseStamped \"{\n  header: {frame_id: 'map'},\n  pose: {\n    position: {x: 5.0, y: 2.0, z: 0.0},\n    orientation: {x: 0.0, y: 0.0, z: 0.0, w: 1.0}\n  }\n}\"\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Python"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped\n\nclass NavigationGoalNode(Node):\n    def __init__(self):\n        super().__init__('nav_goal')\n        self.goal_pub = self.create_publisher(PoseStamped, '/goal_pose', 10)\n\n        # Send goal after 2 seconds\n        self.timer = self.create_timer(2.0, self.send_goal)\n\n    def send_goal(self):\n        goal = PoseStamped()\n        goal.header.frame_id = 'map'\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.pose.position.x = 5.0\n        goal.pose.position.y = 2.0\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n        self.get_logger().info('Navigation goal sent')\n        self.timer.cancel()\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = NavigationGoalNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"RViz (Interactive)"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:'1. Open RViz\n2. Add Nav2 panel: Panels \u2192 Add New Panel \u2192 Nav2\n3. Click "2D Goal Pose" button\n4. Click on map to set goal\n5. Robot navigates autonomously\n'})}),"\n",(0,a.jsx)(e.h2,{id:"troubleshooting-vslam",children:"Troubleshooting VSLAM"}),"\n",(0,a.jsx)(e.h3,{id:"problem-tracking-lost",children:"Problem: Tracking Lost"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Symptoms"}),": ",(0,a.jsx)(e.code,{children:"tracking_vo_state"})," = 0 (lost)"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Moving too fast"}),"\n",(0,a.jsx)(e.li,{children:"Insufficient features (blank wall, darkness)"}),"\n",(0,a.jsx)(e.li,{children:"Camera obstructed"}),"\n",(0,a.jsx)(e.li,{children:"Sudden lighting change"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Move slower"}),"\n",(0,a.jsx)(e.li,{children:"Point camera at textured surfaces"}),"\n",(0,a.jsx)(e.li,{children:"Improve lighting"}),"\n",(0,a.jsxs)(e.li,{children:["Enable image denoising: ",(0,a.jsx)(e.code,{children:"enable_image_denoising: true"})]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"problem-drift-map-not-closing",children:"Problem: Drift (Map Not Closing)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Symptoms"}),": Robot returns to start, but map shows offset."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"No loop closure"}),"\n",(0,a.jsx)(e.li,{children:"Insufficient overlap with starting location"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Ensure robot revisits starting area (same viewpoint)"}),"\n",(0,a.jsxs)(e.li,{children:["Increase ",(0,a.jsx)(e.code,{children:"num_images_for_loop_closure"})," parameter"]}),"\n",(0,a.jsxs)(e.li,{children:["Check loop closure detections: ",(0,a.jsx)(e.code,{children:"/visual_slam/vis/loop_closure_cloud"})]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"problem-poor-performance-low-fps",children:"Problem: Poor Performance (Low FPS)"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Symptoms"}),": FPS < 30, high latency"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"CPU/GPU overloaded"}),"\n",(0,a.jsx)(e.li,{children:"High-resolution images"}),"\n",(0,a.jsx)(e.li,{children:"Too many features tracked"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Reduce image resolution: 640x480 instead of 1920x1080"}),"\n",(0,a.jsxs)(e.li,{children:["Reduce feature count: ",(0,a.jsx)(e.code,{children:"max_num_features: 200"})," (default: 500)"]}),"\n",(0,a.jsxs)(e.li,{children:["Run headless (no visualization): ",(0,a.jsx)(e.code,{children:"enable_slam_visualization: false"})]}),"\n",(0,a.jsx)(e.li,{children:"Close other applications"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"advanced-multi-camera-vslam",children:"Advanced: Multi-Camera VSLAM"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Using 3+ cameras"})," for 360\xb0 coverage:"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"Node(\n    package='isaac_ros_visual_slam',\n    executable='isaac_ros_visual_slam',\n    parameters=[{\n        'num_cameras': 4,  # 4 cameras\n    }],\n    remappings=[\n        ('/camera_0/image', '/front_camera/image_raw'),\n        ('/camera_1/image', '/left_camera/image_raw'),\n        ('/camera_2/image', '/right_camera/image_raw'),\n        ('/camera_3/image', '/back_camera/image_raw'),\n        # ... camera_info for each\n    ]\n)\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Benefits"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"No blind spots"}),"\n",(0,a.jsx)(e.li,{children:"More robust tracking"}),"\n",(0,a.jsx)(e.li,{children:"Better loop closure"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"performance-tuning",children:"Performance Tuning"}),"\n",(0,a.jsx)(e.h3,{id:"parameters-for-speed",children:"Parameters for Speed"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"visual_slam:\n  ros__parameters:\n    # Reduce features for speed\n    max_num_features: 150  # Default: 500\n\n    # Disable expensive operations\n    enable_slam_visualization: false\n    enable_landmarks_view: false\n    enable_observations_view: false\n\n    # Lower image resolution (at camera driver level)\n    # RealSense: width: 640, height: 480\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Result"}),": 60+ FPS \u2192 90+ FPS"]}),"\n",(0,a.jsx)(e.h3,{id:"parameters-for-accuracy",children:"Parameters for Accuracy"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"visual_slam:\n  ros__parameters:\n    # Increase features for accuracy\n    max_num_features: 800\n\n    # Enable denoising\n    enable_image_denoising: true\n\n    # Enable loop closure\n    enable_loop_closure: true\n    num_images_for_loop_closure: 50\n\n    # Higher frequency IMU\n    imu_jitter_time_s: 0.001\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Result"}),": Better accuracy, lower drift, but slower (40-50 FPS)."]}),"\n",(0,a.jsx)(e.h2,{id:"comparison-cuvslam-vs-orb-slam3",children:"Comparison: cuVSLAM vs. ORB-SLAM3"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Feature"}),(0,a.jsx)(e.th,{children:"cuVSLAM"}),(0,a.jsx)(e.th,{children:"ORB-SLAM3"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Platform"})}),(0,a.jsx)(e.td,{children:"GPU (Jetson, NVIDIA GPU)"}),(0,a.jsx)(e.td,{children:"CPU"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Speed"})}),(0,a.jsx)(e.td,{children:"60 FPS (Jetson Orin)"}),(0,a.jsx)(e.td,{children:"10-20 FPS"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Accuracy"})}),(0,a.jsx)(e.td,{children:"Excellent"}),(0,a.jsx)(e.td,{children:"Excellent"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Map Persistence"})}),(0,a.jsx)(e.td,{children:"Yes (save/load)"}),(0,a.jsx)(e.td,{children:"Yes"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"IMU Fusion"})}),(0,a.jsx)(e.td,{children:"Yes"}),(0,a.jsx)(e.td,{children:"Yes"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"License"})}),(0,a.jsx)(e.td,{children:"Apache 2.0"}),(0,a.jsx)(e.td,{children:"GPLv3"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"ROS 2 Integration"})}),(0,a.jsx)(e.td,{children:"Native (Isaac ROS)"}),(0,a.jsx)(e.td,{children:"Community packages"})]})]})]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Recommendation"}),": Use cuVSLAM if you have NVIDIA hardware (Jetson or RTX GPU)."]}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsx)(e.p,{children:"You've mastered VSLAM and navigation. Next, apply navigation to bipedal humanoid robots."}),"\n",(0,a.jsxs)(e.p,{children:["\ud83d\udc49 ",(0,a.jsx)(e.strong,{children:(0,a.jsx)(e.a,{href:"nav2-bipedal",children:"Next: Nav2 for Bipedal Robots \u2192"})})]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.admonition,{title:"VSLAM Tips",type:"tip",children:(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Good lighting"}),": VSLAM needs sufficient light and texture"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Slow movements"}),": Moving < 0.5 m/s prevents tracking loss"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Loop closure"}),": Revisit starting area to close the map"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Save maps"}),": Reuse maps for faster startup (localization mode)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Monitor covariance"}),": Low covariance = high confidence"]}),"\n"]})}),"\n",(0,a.jsx)(e.h2,{id:"lab-exercise",children:"Lab Exercise"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Build a complete VSLAM-based navigation system"}),":"]}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Setup"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"RealSense D435i on Jetson Orin Nano"}),"\n",(0,a.jsx)(e.li,{children:"Launch cuVSLAM in mapping mode"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Create map"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Teleoperate robot through environment"}),"\n",(0,a.jsx)(e.li,{children:"Cover all rooms/areas"}),"\n",(0,a.jsx)(e.li,{children:"Return to start (trigger loop closure)"}),"\n",(0,a.jsx)(e.li,{children:"Save map to file"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Test localization"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Restart cuVSLAM in localization mode"}),"\n",(0,a.jsx)(e.li,{children:"Place robot at random location"}),"\n",(0,a.jsx)(e.li,{children:"Verify it localizes correctly"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Add Nav2"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Launch Nvblox (3D mapping)"}),"\n",(0,a.jsx)(e.li,{children:"Launch Nav2 navigation stack"}),"\n",(0,a.jsx)(e.li,{children:"Send navigation goal via RViz"}),"\n",(0,a.jsx)(e.li,{children:"Robot navigates autonomously"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Measure performance"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Record FPS: ",(0,a.jsx)(e.code,{children:"ros2 topic hz /visual_slam/tracking/odometry"})]}),"\n",(0,a.jsx)(e.li,{children:"Measure drift: Return to start, compare pose"}),"\n",(0,a.jsx)(e.li,{children:"Test in different lighting conditions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Bonus"}),": Implement waypoint navigation (visit multiple goals sequentially)."]})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>o});var s=i(6540);const a={},l=s.createContext(a);function r(n){const e=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:r(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);